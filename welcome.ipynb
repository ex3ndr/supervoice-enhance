{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98054923-acec-4707-be8f-4466eb6030bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from IPython.display import Audio, display\n",
    "from supervoice_enhance.model import EnhanceModel \n",
    "from supervoice_enhance.audio import load_mono_audio, spectogram\n",
    "from supervoice_enhance.config import config\n",
    "from training.effects import default_noisy_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e90e8a-c69a-4622-8304-54b20a95acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distortion Pipeline\n",
    "rir_files = []\n",
    "with open('./external_datasets/rir-1/files.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        rir_files.append(\"./external_datasets/rir-1/\" + line.strip())\n",
    "pipeline = default_noisy_pipeline(rir_files)\n",
    "\n",
    "# Model\n",
    "device = \"cpu\"\n",
    "vocoder = torch.hub.load(repo_or_dir='ex3ndr/supervoice-vocoder', model='bigvsan')\n",
    "flow = torch.hub.load(repo_or_dir='ex3ndr/supervoice-flow', model='flow')\n",
    "direct_flow = torch.hub.load(repo_or_dir='ex3ndr/supervoice-flow', model='flow')\n",
    "checkpoint = torch.load(f'./output/ft-05.pt', map_location=\"cpu\")\n",
    "enhance = EnhanceModel(flow, config)\n",
    "enhance.load_state_dict(checkpoint['model'])\n",
    "direct_flow.to(device)\n",
    "direct_flow.eval()\n",
    "vocoder.to(device)\n",
    "vocoder.eval()\n",
    "enhance.to(device)\n",
    "enhance.eval()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0e8cf-9491-4289-97d7-a06117b302bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_vocoder(src):\n",
    "    with torch.no_grad():\n",
    "        return vocoder.generate(src)\n",
    "\n",
    "def do_enhance(src, steps = 8):\n",
    "    src = (src - config.audio.norm_mean) / config.audio.norm_std\n",
    "    pr = enhance.sample(source = src.to(torch.float32), steps = steps)\n",
    "    return ((pr * config.audio.norm_std) + config.audio.norm_mean).to(torch.float32)\n",
    "\n",
    "def do_flow(src, steps = 8):\n",
    "    src = (src - config.audio.norm_mean) / config.audio.norm_std\n",
    "    pr, _ = direct_flow.sample(audio = src.to(torch.float32), steps = steps)\n",
    "    return ((pr * config.audio.norm_std) + config.audio.norm_mean).to(torch.float32)\n",
    "\n",
    "def do_distort(src):\n",
    "    return pipeline.apply(src, config.audio.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd8eb5-a948-4f67-a580-19d315385920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source file\n",
    "source_file = \"./external_datasets/libritts-r/test-clean/1320/122617/1320_122617_000001_000000.wav\"\n",
    "source_raw = load_mono_audio(source_file, sample_rate = config.audio.sample_rate)\n",
    "\n",
    "# Distort audio\n",
    "distorted = do_distort(source_raw)\n",
    "\n",
    "# Pad audio\n",
    "source = distorted\n",
    "target_length = 5 * config.audio.sample_rate\n",
    "current_length = source.shape[0]\n",
    "padding_length = target_length - current_length\n",
    "source = F.pad(source, (0, padding_length), mode='constant')\n",
    "\n",
    "# Get spectogram\n",
    "spec = spectogram(source, \n",
    "    n_fft = config.audio.n_fft, \n",
    "    n_mels = config.audio.n_mels, \n",
    "    n_hop = config.audio.hop_size, \n",
    "    n_window = config.audio.win_size,  \n",
    "    mel_norm = config.audio.mel_norm, \n",
    "    mel_scale = config.audio.mel_scale, \n",
    "    sample_rate = config.audio.sample_rate\n",
    ")\n",
    "\n",
    "# Vocode back\n",
    "source_rec = do_vocoder(spec.to(device).unsqueeze(0)).squeeze(0)\n",
    "display(Audio(data=source_raw.cpu(), rate=config.audio.sample_rate))\n",
    "display(Audio(data=source_rec.cpu(), rate=config.audio.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09fdbc-aad0-45b2-bd6e-ab9f5da28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced = do_enhance(spec.to(device).transpose(0, 1), 8)\n",
    "enhanced_rec = do_vocoder(enhanced.transpose(0, 1).to(device).unsqueeze(0)).squeeze(0)\n",
    "display(Audio(data=enhanced_rec.cpu(), rate=config.audio.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70aa4f1-aadd-4cf2-a951-b874bb2bae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_out = do_flow(spec.transpose(0, 1), 8)\n",
    "flow_out_rec = do_vocoder(flow_out.transpose(0, 1).to(device).unsqueeze(0)).squeeze(0)\n",
    "display(Audio(data=flow_out_rec.cpu(), rate=config.audio.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd9b36-b187-4e8f-8140-ad54d998591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.effects import maybe, rir, one_of, low_pass, reverbate, SoxEffect\n",
    "pipeline = one_of(\n",
    "    rir(rir_files),\n",
    "    maybe(one_of(\n",
    "        low_pass(),\n",
    "        reverbate()\n",
    "    ), 0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0a328-9081-438a-a2e3-0bcb4361616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173f612-a87a-4036-8fac-0be8de03e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
